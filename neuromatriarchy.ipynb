{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RMhGdYHuOZM8"
   },
   "source": [
    "# Neuromatriarchy\n",
    "\n",
    "This notebook is based on [Deep Dream](https://github.com/google/deepdream/blob/master/dream.ipynb) notebook and is used for developer's convinience.\n",
    "\n",
    "It'll be interesting to see what imagery people are able to generate using the described technique. If you post images to Google+, Facebook, or Twitter, be sure to tag them with **#deepdream** so other researchers can check them out too.\n",
    "\n",
    "##Dependencies\n",
    "The Neuromatriarchy progect inherrits dependencies from Deep Dream:\n",
    "* Standard Python scientific stack: [NumPy](http://www.numpy.org/), [SciPy](http://www.scipy.org/), [PIL](http://www.pythonware.com/products/pil/), [IPython](http://ipython.org/). Those libraries can also be installed as a part of one of the scientific packages for Python, such as [Anaconda](http://continuum.io/downloads) or [Canopy](https://store.enthought.com/).\n",
    "* [Caffe](http://caffe.berkeleyvision.org/) deep learning framework ([installation instructions](http://caffe.berkeleyvision.org/installation.html)).\n",
    "* Google [protobuf](https://developers.google.com/protocol-buffers/) library that is used for Caffe model manipulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab_type": "code",
    "collapsed": false,
    "id": "Pqz5k4syOZNA"
   },
   "outputs": [],
   "source": [
    "# imports and basic notebook setup\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import caffe\n",
    "\n",
    "# If your GPU supports CUDA and Caffe was built with CUDA support,\n",
    "# uncomment the following to run Caffe operations on the GPU.\n",
    "# caffe.set_mode_gpu()\n",
    "# caffe.set_device(0) # select GPU device if multiple devices exist\n",
    "\n",
    "from np_array_utils import *\n",
    "from dream_utils import *\n",
    "from obsession_utils import *\n",
    "\n",
    "# Original emotion recognition model\n",
    "model_path = '/Users/sitin/Documents/Workspace/caffe/models/VGG_S_rgb/' # substitute your path here\n",
    "    \n",
    "emotions = Dreamer(\n",
    "    net_fn=model_path + 'deploy.txt',\n",
    "    param_fn=model_path + 'EmotiW_VGG_S.caffemodel',\n",
    "    end_level='pool5'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UeV_fJ4QOZNb"
   },
   "source": [
    "##  Producing dreams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QrcdU-lmOZNx"
   },
   "source": [
    "Here we will start from the death mask of delightful [Louise of Mecklenburg-Strelitz](https://en.wikipedia.org/wiki/Louise_of_Mecklenburg-Strelitz):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab_type": "code",
    "collapsed": false,
    "executionInfo": null,
    "id": "40p5AqqwOZN5",
    "outputId": "f62cde37-79e8-420a-e448-3b9b48ee1730",
    "pinned": false
   },
   "outputs": [],
   "source": [
    "louise_img = np.float32(PIL.Image.open('images/louise.jpg'))\n",
    "showarray(louise_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z9_215_GOZOL"
   },
   "source": [
    "Running the next code cell starts the detail generation process. You may see how new patterns start to form, iteration by iteration, octave by octave."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotion_stages=['conv5', 'conv3', 'conv4', 'conv4', 'conv4']\n",
    "    \n",
    "dream = emotions.long_dream(louise_img, stages=emotion_stages, resize_in=(224, 224), resize_out=(800, 800))\n",
    "showarray(dream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "both",
    "colab_type": "code",
    "collapsed": false,
    "id": "OIepVN6POZOc"
   },
   "outputs": [],
   "source": [
    "emotions.net.blobs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Controlling dreams\n",
    "\n",
    "The image detail generation method described above tends to produce some patterns more often the others. One easy way to improve the generated image diversity is to tweak the optimization objective. Here we show just one of many ways to do that. Let's use one more input image. We'd call it a \"*guide*\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "guide = np.float32(PIL.Image.open('images/pattern_city.jpg'))\n",
    "guide = resizearray(guide, 224, 224)\n",
    "showarray(guide)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we pick some target layer and extract guide image features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "obsession_end = 'conv4'\n",
    "dst, guide_features = define_obsession(emotions.net, end=obsession_end, guide=guide)\n",
    "objective_guide = make_objective_guide(guide_features)\n",
    "\n",
    "_=emotions.deepdream(louise_img, end=obsession_end, objective=objective_guide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colabVersion": "0.3.1",
  "default_view": {},
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  },
  "views": {}
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
